{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"AfQSK4jxch9b"},"source":["# Problems 3\n","\n"]},{"cell_type":"markdown","metadata":{"id":"PlGyGi-ych9e"},"source":["Name: Denitsa Ilieva"]},{"cell_type":"code","metadata":{"id":"tQMFuq1Ych9e"},"source":["# You may not use numpy in this exercise\n","import re\n","import pandas as pd\n","import copy\n","from sklearn.model_selection import train_test_split\n","# Fill in any place that says 'Your code here'.\n","# You can implement auxiliary methods if you deem it proper. You may also change or extend functions, but:\n","# Make sure the code blocks at the end of each problem run as intended!!!"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NPpv29Xwch9g"},"source":["***\n","\n","\n","# Problem 1\n","\n","Solve the following exercises using the code templates given below (fill out the missing code):\n","1. Represent the data as 9-dimensional vectors of features counting occurrences of the terms *Verband*, *Struktur*, *Lehre*, *Körper*, *Teilgebiet*, *Person(en)*, *Krankheit*, *Medizin*, *Sinne*. You can define the list of terms as a global variable.\n","2. Separate text 1 \"*Der Begriff Verband ... erweitert.*\" as test data.\n","\n","Hints:\n"," * You may want to remember what you have learned about regular expressions and how to use them in Python.\n"," * Labels for each datapoint (text) are provided in `corpus.txt`. Be sure to look at the file in order to parse the dataset correctly."]},{"cell_type":"code","metadata":{"id":"ZcCVD0-Wch9h"},"source":["terms = ['Verband', 'Struktur', 'Lehre', 'Körper', 'Teilgebiet', 'Personen', 'Krankheit', 'Medizin', 'Sinne']    # hardcode the terms\n","\n","\n","def read_corpus(filename):\n","    \"\"\"\n","    Reads an annotated corpus into a list.\n","    Args:\n","    filename -- str -- The name of the corpus file.\n","    Returns:\n","    documents -- list -- A list of all documents with their corresponding label.\n","    \"\"\"\n","    # YOUR CODE HERE\n","    df = pd.read_csv(filename, sep=\"\\t\", header=None, names=[\"content\", \"labels\"])\n","\n","    remove = ['\\n', '\\(', '\\)', '\\,', '\\.', '\\„', '\\“','\\:']\n","    for rem in remove:\n","      df['content'] = df['content'].replace(rem,'',regex=True)\n","\n","    \"\"\"\n","    or with list --> but it isn't so clearly\n","    documents = []\n","    with open(filename) as f:\n","      for line in f:\n","        remove = ['\\n', '(', ')', ',', '.', '„', '“', ':']\n","        for r in remove:\n","          line = line.replace(r,'')\n","        line = line.split('\\t')\n","        documents.append(line)\"\"\"\n","\n","    return df\n","\n","\n","def get_vectors(docs):\n","    \"\"\"\n","    Converts some documents into feature vectors.\n","    Args:\n","    docs -- list -- A list of all documents with their corresponding label.\n","    Returns:\n","    vectors -- list -- A list of all document vectors with their corresponding label.\n","    \"\"\"\n","    # YOUR CODE HERE\n","    vectorized_array = []\n","    vectorized_matrix = []\n","\n","    for row in docs['content']:\n","      vectorized_array = [0,0,0,0,0,0,0,0,0]\n","      row = row.split(' ')\n","      for r in row:\n","        for t in range(len(terms)):\n","          if r == terms[t]:\n","            #print(terms[t])\n","            vectorized_array[t] = 1\n","          #print(vectorized_array)\n","      vectorized_matrix.append(vectorized_array)\n","\n","    df = pd.DataFrame(vectorized_matrix, columns=terms)\n","    df['labels'] = pd.Series(docs['labels'])\n","\n","    return df\n","\n"," ############# I am not sure that I understood the purpose of this feature correctly ############################\n"," ############# Here I have counted the total number of terms that appear in the document ########################\n","def count_term(document):\n","    \"\"\"\n","    Counts the number a given term appears in the given document.\n","    Args:\n","    term -- str -- A regular expression or simple string representing the search term.\n","    document -- str -- The search document.\n","    Returns:\n","    integer -- How many matches for term were found in document.\n","    \"\"\"\n","    # YOUR CODE HERE\n","    vectorized_array = []\n","    vectorized_matrix = []\n","\n","    for row in document['content']:\n","      vectorized_array = [0,0,0,0,0,0,0,0,0]\n","      row = row.split(' ')\n","      for r in row:\n","        for t in range(len(terms)):\n","          if r == terms[t]:\n","            #print(terms[t])\n","            vectorized_array[t] += 1\n","          #print(vectorized_array)\n","      vectorized_matrix.append(vectorized_array)\n","\n","    df = pd.DataFrame(vectorized_matrix, columns=terms)\n","    df['labels'] = pd.Series(document['labels'])\n","\n","    return df\n","\n","\n","\n","def split_train_test(data):\n","     # YOUR CODE HERE\n","     # test_size by default = 0.25\n","\n","    X = data.iloc[1:,:]\n","    y = data.iloc[:1,:]\n","\n","    return X,y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vMnrgZBRlFlU"},"source":["corpus = read_corpus(\"corpus.txt\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":352},"id":"TuvcJ9PSlNdF","executionInfo":{"status":"ok","timestamp":1638218672644,"user_tz":-60,"elapsed":353,"user":{"displayName":"Denitsa Ilieva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10873287225646224114"}},"outputId":"bf018461-5f65-428e-bb99-c0c073ae394b"},"source":["corpus"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>content</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Der Begriff Verband steht für eine Vielzahl se...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>In der Mathematik ist ein Verband eine bestimm...</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Ein Körper ist im mathematischen Teilgebiet de...</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Eine Wunde lat Vulnus griech Trauma ist die Tr...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Der Körper von lat corpus ist im biologischen ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Die Anatomie aus altgriechisch ἀνά aná auf und...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Die Medizin von lateinisch ars medicina Heilku...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Körperschaften sind auf der Mitgliedschaft von...</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Krankheit vom mittelhochdeutschen krancheit kr...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Organe im rechtlichen Sinne handeln für jurist...</td>\n","      <td>-1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                             content  labels\n","0  Der Begriff Verband steht für eine Vielzahl se...       1\n","1  In der Mathematik ist ein Verband eine bestimm...      -1\n","2  Ein Körper ist im mathematischen Teilgebiet de...      -1\n","3  Eine Wunde lat Vulnus griech Trauma ist die Tr...       1\n","4  Der Körper von lat corpus ist im biologischen ...       1\n","5  Die Anatomie aus altgriechisch ἀνά aná auf und...       1\n","6  Die Medizin von lateinisch ars medicina Heilku...       1\n","7  Körperschaften sind auf der Mitgliedschaft von...      -1\n","8  Krankheit vom mittelhochdeutschen krancheit kr...       1\n","9  Organe im rechtlichen Sinne handeln für jurist...      -1"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"RcYfWkK4rqlB"},"source":["labeled_vectors = get_vectors(corpus)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":352},"id":"E1yUSN5jsWVT","executionInfo":{"status":"ok","timestamp":1638218675418,"user_tz":-60,"elapsed":227,"user":{"displayName":"Denitsa Ilieva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10873287225646224114"}},"outputId":"c7f93dc3-254b-48d2-8bdb-8c98cf26aea8"},"source":["labeled_vectors"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Verband</th>\n","      <th>Struktur</th>\n","      <th>Lehre</th>\n","      <th>Körper</th>\n","      <th>Teilgebiet</th>\n","      <th>Personen</th>\n","      <th>Krankheit</th>\n","      <th>Medizin</th>\n","      <th>Sinne</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>-1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Verband  Struktur  Lehre  Körper  ...  Krankheit  Medizin  Sinne  labels\n","0        1         0      0       1  ...          0        0      1       1\n","1        1         1      0       0  ...          0        0      0      -1\n","2        0         1      0       1  ...          0        0      0      -1\n","3        0         0      0       0  ...          1        0      0       1\n","4        0         0      0       1  ...          0        0      1       1\n","5        0         1      1       0  ...          0        1      0       1\n","6        0         0      1       0  ...          0        1      0       1\n","7        0         0      0       0  ...          0        0      0      -1\n","8        0         0      0       0  ...          1        0      0       1\n","9        0         0      0       0  ...          0        0      1      -1\n","\n","[10 rows x 10 columns]"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hSkiPnpOoIMj","executionInfo":{"status":"ok","timestamp":1638218676706,"user_tz":-60,"elapsed":21,"user":{"displayName":"Denitsa Ilieva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10873287225646224114"}},"outputId":"c9827f95-4fce-487e-8b14-ce1e3b718321"},"source":["labeled_vectors.info()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 10 entries, 0 to 9\n","Data columns (total 10 columns):\n"," #   Column      Non-Null Count  Dtype\n","---  ------      --------------  -----\n"," 0   Verband     10 non-null     int64\n"," 1   Struktur    10 non-null     int64\n"," 2   Lehre       10 non-null     int64\n"," 3   Körper      10 non-null     int64\n"," 4   Teilgebiet  10 non-null     int64\n"," 5   Personen    10 non-null     int64\n"," 6   Krankheit   10 non-null     int64\n"," 7   Medizin     10 non-null     int64\n"," 8   Sinne       10 non-null     int64\n"," 9   labels      10 non-null     int64\n","dtypes: int64(10)\n","memory usage: 928.0 bytes\n"]}]},{"cell_type":"code","metadata":{"id":"chBYVTUb8443"},"source":["training_data, test_data = split_train_test(labeled_vectors)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":322},"id":"JG9S7Yl0C1gA","executionInfo":{"status":"ok","timestamp":1638218679793,"user_tz":-60,"elapsed":230,"user":{"displayName":"Denitsa Ilieva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10873287225646224114"}},"outputId":"00ea381b-d140-450e-8991-b1c01ba6064c"},"source":["training_data"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Verband</th>\n","      <th>Struktur</th>\n","      <th>Lehre</th>\n","      <th>Körper</th>\n","      <th>Teilgebiet</th>\n","      <th>Personen</th>\n","      <th>Krankheit</th>\n","      <th>Medizin</th>\n","      <th>Sinne</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>-1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Verband  Struktur  Lehre  Körper  ...  Krankheit  Medizin  Sinne  labels\n","1        1         1      0       0  ...          0        0      0      -1\n","2        0         1      0       1  ...          0        0      0      -1\n","3        0         0      0       0  ...          1        0      0       1\n","4        0         0      0       1  ...          0        0      1       1\n","5        0         1      1       0  ...          0        1      0       1\n","6        0         0      1       0  ...          0        1      0       1\n","7        0         0      0       0  ...          0        0      0      -1\n","8        0         0      0       0  ...          1        0      0       1\n","9        0         0      0       0  ...          0        0      1      -1\n","\n","[9 rows x 10 columns]"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":78},"id":"mlXPsZ9BC5qw","executionInfo":{"status":"ok","timestamp":1638218681426,"user_tz":-60,"elapsed":273,"user":{"displayName":"Denitsa Ilieva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10873287225646224114"}},"outputId":"8dc5de39-e743-452a-a5db-e2f0c328c1ab"},"source":["test_data"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Verband</th>\n","      <th>Struktur</th>\n","      <th>Lehre</th>\n","      <th>Körper</th>\n","      <th>Teilgebiet</th>\n","      <th>Personen</th>\n","      <th>Krankheit</th>\n","      <th>Medizin</th>\n","      <th>Sinne</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Verband  Struktur  Lehre  Körper  ...  Krankheit  Medizin  Sinne  labels\n","0        1         0      0       1  ...          0        0      1       1\n","\n","[1 rows x 10 columns]"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":352},"id":"FqQktwXBEfO-","executionInfo":{"status":"ok","timestamp":1638218682999,"user_tz":-60,"elapsed":214,"user":{"displayName":"Denitsa Ilieva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10873287225646224114"}},"outputId":"4a157735-8537-49d1-bac2-76219f9d40f0"},"source":["count_term(corpus)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Verband</th>\n","      <th>Struktur</th>\n","      <th>Lehre</th>\n","      <th>Körper</th>\n","      <th>Teilgebiet</th>\n","      <th>Personen</th>\n","      <th>Krankheit</th>\n","      <th>Medizin</th>\n","      <th>Sinne</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>-1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Verband  Struktur  Lehre  Körper  ...  Krankheit  Medizin  Sinne  labels\n","0        1         0      0       1  ...          0        0      1       1\n","1        1         1      0       0  ...          0        0      0      -1\n","2        0         1      0       1  ...          0        0      0      -1\n","3        0         0      0       0  ...          1        0      0       1\n","4        0         0      0       4  ...          0        0      1       1\n","5        0         1      1       0  ...          0        1      0       1\n","6        0         0      1       0  ...          0        1      0       1\n","7        0         0      0       0  ...          0        0      0      -1\n","8        0         0      0       0  ...          1        0      0       1\n","9        0         0      0       0  ...          0        0      2      -1\n","\n","[10 rows x 10 columns]"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"iVLR7ZtLch9l"},"source":["***\n","\n","# Problem 2\n","\n","Implement the Multinomial Naive Bayes algorithm. Train it on the 9 training texts and\n","predict the class of the test text of `corpus.txt`. <br>\n","**Please write your own functions for the vector operations.**\n"]},{"cell_type":"code","metadata":{"id":"b4jssYC1ch9m"},"source":["def naive_bayes_model(vectors):\n","    \"\"\"\n","    Trains a Naive Bayes model for binary classification on some vectors.\n","\n","    Args:\n","    vectors -- list -- A list of all document vectors with their corresponding label.\n","\n","    Returns:\n","    number_pos_docs -- integer -- The number of training documents that are labeled as positive.\n","    number_neg_docs -- integer -- The number of training documents that are labeled as negative.\n","    pos_vector -- list -- The vector sum for all positive training documents.\n","    neg_vector -- list -- The vector sum for all negative training documents.\n","\n","    \"\"\"\n","    # YOUR CODE HERE\n","    number_pos_docs = 0\n","    number_neg_docs = 0\n","    pos_vector = [0,0,0,0,0,0,0,0,0]\n","    neg_vector = [0,0,0,0,0,0,0,0,0]\n","    for i in vectors[vectors.columns[-1]]:\n","      if i == 1:\n","        number_pos_docs += 1\n","      else:\n","        number_neg_docs += 1\n","\n","    for k,j in zip(vectors.itertuples(), vectors[vectors.columns[-1]]):\n","      #print('k:',list(k[1:10]))\n","      if j == 1:\n","        pos_vector = [pos_vector[x] + list(k[1:10])[x] for x in range(len(pos_vector))]\n","      else:\n","        neg_vector = [neg_vector[x] + list(k[1:10])[x] for x in range(len(neg_vector))]\n","\n","    return number_pos_docs, number_neg_docs, pos_vector, neg_vector\n","\n","\n","def naive_bayes_prediction(test_vector, document_vectors):\n","    \"\"\"\n","    Calculates the scores for the positive and negative classes for a test vector.\n","\n","    Args:\n","    test_vector -- list -- A list of numbers.\n","\n","    \"\"\"\n","    ################### I compute the prediction and the final result ONLY int his fiúnction ##########################\n","    ################### it's not the optimized version, but it's according to the calculation of the formula ##########\n","    number_pos_docs, number_neg_docs, pos_vector, neg_vector = naive_bayes_model(document_vectors)\n","\n","    # YOUR CODE HERE\n","    p_pos = number_pos_docs/(number_pos_docs+number_neg_docs)\n","\n","    max_pos_value = 0\n","    for p in pos_vector:\n","      max_pos_value += p\n","    #print('max pos value is', max_pos_value)\n","\n","    p_feat_all = []\n","\n","    for i,row in test_vector.iterrows():\n","      p_feat = []\n","      for c in range(len(test_vector.columns[:9])):\n","        #print('c is', c)\n","        p_y = 0\n","        if row[c] == 1:\n","          #print('row c is 1', pos_vector[c])\n","          p_y = pos_vector[c]/max_pos_value\n","          #print('p-y is', p_y)\n","\n","          p_feat.append(p_y)\n","      p_feat_all.append(p_feat)\n","\n","    #print(p_feat_all)\n","\n","    for i in p_feat_all:\n","      probability_pos = 1\n","      for k in i:\n","        probability_pos *= k\n","      print('Probability positive for the positive value features {} is {}'.format(i,probability_pos*p_pos))\n","\n","\n","\n","    p_neg = number_neg_docs/(number_pos_docs+number_neg_docs)\n","\n","    max_neg_value = 0\n","    for p in neg_vector:\n","      max_neg_value += p\n","    #print('max neg value is', max_neg_value)\n","\n","    p_feat_all_neg = []\n","\n","    for i,row in test_vector.iterrows():\n","      p_feat_neg = []\n","      for c in range(len(test_vector.columns[:9])):\n","        #print('c is', c)\n","        p_y_n = 0\n","        if row[c] == 1:\n","          #print('row c is 1', pos_vector[c])\n","          p_y_n = neg_vector[c]/max_neg_value\n","          #print('p-y-n is', p_y_n)\n","\n","          p_feat_neg.append(p_y_n)\n","      p_feat_all_neg.append(p_feat_neg)\n","\n","    #print(p_feat_all)\n","\n","    for i in p_feat_all_neg:\n","      probability_neg = 1\n","      for k in i:\n","        probability_neg *= k\n","      print('Probability negative for the negative value features {} is {}'.format(i,probability_neg*p_neg))\n","\n","\n","    #print(\"+ {}\\n- {}\".format(probability_pos, probability_neg))\n","\n","\n","def sum_list_of_vectors(vlist):\n","    \"\"\"\n","    Sums all vectors in a list elementwise.\n","\n","    Args:\n","    vlist -- list -- A list of vectors.\n","\n","    Returns:\n","    sumv -- list -- The elementwise sum of all vectors in vlist.\n","    \"\"\"\n","    # YOUR CODE HERE\n","    pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q7kraxG5op1C","executionInfo":{"status":"ok","timestamp":1638218690631,"user_tz":-60,"elapsed":308,"user":{"displayName":"Denitsa Ilieva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10873287225646224114"}},"outputId":"e1dfe9e5-f92d-4620-e160-8f3767f3a4ba"},"source":["naive_bayes_model(training_data)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5, 4, [0, 1, 2, 1, 1, 0, 2, 2, 1], [1, 2, 0, 1, 1, 2, 0, 0, 1])"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"j04nT8tLch9o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638218693353,"user_tz":-60,"elapsed":197,"user":{"displayName":"Denitsa Ilieva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10873287225646224114"}},"outputId":"3eb106b2-070a-47f6-e43d-a5fb905325b6"},"source":["naive_bayes_prediction(test_data, training_data)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Probability positive for the positive value features [0.0, 0.1, 0.1] is 0.0\n","Probability negative for the negative value features [0.125, 0.125, 0.125] is 0.0008680555555555555\n"]}]},{"cell_type":"markdown","metadata":{"id":"4V8ptwhoch9p"},"source":["***\n","\n","# Problem 3\n","\n","Modify the prediction function to allow for add-1 smoothing.\n","Compare the results to unsmoothed Naive Bayes."]},{"cell_type":"code","metadata":{"id":"WrBKTgYEch9p"},"source":["def naive_bayes_prediction(test_vector, document_vectors, smoothing=True):\n","    \"\"\"\n","    Calculates the scores for the positive and negative classes for a test vector.\n","\n","    Args:\n","    test_vector -- list -- A labeled document vector.\n","    document_vectors -- list -- A list of labeles document vectors.\n","    smoothing -- bool -- Optional, indicates whether +1 smoothing should be used or not.\n","    \"\"\"\n","    number_pos_docs, number_neg_docs, pos_vector, neg_vector = naive_bayes_model(document_vectors)\n","\n","    # YOUR CODE HERE\n","    p_pos = number_pos_docs/(number_pos_docs+number_neg_docs)\n","\n","    max_pos_value = 0\n","    for p in pos_vector:\n","      max_pos_value += p\n","\n","    p_feat_all = []\n","\n","    for i,row in test_vector.iterrows():\n","      p_feat = []\n","      for c in range(len(test_vector.columns[:9])):\n","        p_y = 0\n","        if row[c] == 1:\n","          p_y = pos_vector[c]/max_pos_value\n","\n","          p_feat.append(p_y)\n","      p_feat_all.append(p_feat)\n","\n","    for i in p_feat_all:\n","      probability_pos = 1\n","      for k in i:\n","        k = k + (1/max_pos_value)\n","        probability_pos *= k\n","      print('Probability positive for the positive value features {} is {}'.format(i,probability_pos*p_pos))\n","\n","    #################### FOR NEGATIVE VALUES###################################\n","    p_neg = number_neg_docs/(number_pos_docs+number_neg_docs)\n","\n","    max_neg_value = 0\n","    for p in neg_vector:\n","      max_neg_value += p\n","\n","    p_feat_all_neg = []\n","\n","    for i,row in test_vector.iterrows():\n","      p_feat_neg = []\n","      for c in range(len(test_vector.columns[:9])):\n","        p_y_n = 0\n","        if row[c] == 1:\n","          p_y_n = neg_vector[c]/max_neg_value\n","\n","          p_feat_neg.append(p_y_n)\n","      p_feat_all_neg.append(p_feat_neg)\n","\n","    for i in p_feat_all_neg:\n","      probability_neg = 1\n","      for k in i:\n","        probability_neg *= (k+1/max_neg_value)\n","      print('Probability negative for the negative value features {} is {}'.format(i,probability_neg*p_neg))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k5oRB7BpwpNr","executionInfo":{"status":"ok","timestamp":1638218707126,"user_tz":-60,"elapsed":326,"user":{"displayName":"Denitsa Ilieva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10873287225646224114"}},"outputId":"ba75da3b-4b12-4136-c1d7-ffcb385c4c83"},"source":["naive_bayes_prediction(test_data, training_data)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Probability positive for the positive value features [0.0, 0.1, 0.1] is 0.0022222222222222227\n","Probability negative for the negative value features [0.125, 0.125, 0.125] is 0.006944444444444444\n"]}]},{"cell_type":"code","metadata":{"id":"7ev1a05Cch9q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637620170981,"user_tz":-60,"elapsed":205,"user":{"displayName":"Denitsa Ilieva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10873287225646224114"}},"outputId":"533b8899-40a1-4b0f-df05-3ebb7f807279"},"source":["naive_bayes_prediction(test_data, training_data, smoothing=True)    # new functionality"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Probability positive for the positive value features [0.1111111111111111, 0.1111111111111111, 0.1111111111111111] is 0.0062708210856359\n","Probability positive for the positive value features [0.1111111111111111, 0.1111111111111111] is 0.02821869488536155\n","Probability positive for the positive value features [0.1111111111111111, 0.1111111111111111] is 0.02821869488536155\n","Probability negative for the negative value features [0.2, 0.0, 0.0] is 0.0068571428571428585\n","Probability negative for the negative value features [0.0, 0.0] is 0.017142857142857144\n","Probability negative for the negative value features [0.0, 0.2] is 0.03428571428571429\n"]}]},{"cell_type":"markdown","metadata":{"id":"j84SGqIHch9q"},"source":["YOUR ANSWER HERE: The results with or without smoothing are not as accurate"]},{"cell_type":"code","metadata":{"id":"KxcaDzPRxtGN"},"source":[],"execution_count":null,"outputs":[]}]}