{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"6c5_EbqIJ59b"},"source":["# Problems 8\n"]},{"cell_type":"markdown","metadata":{"id":"DmE-PIsCJ59d"},"source":["Name: Denitsa Ilieva"]},{"cell_type":"code","metadata":{"id":"O_y6zM4DJ59e"},"source":["import numpy as np\n","import pandas as pd\n","# Fill in any place that says 'Your code here'.\n","# You may change or extend functions, but:\n","# Make sure the code blocks at the end of each problem run as intended!!!\n","\n","# You may copy the methods to read the iris data from your solution to Problems 6"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jmPdJMyhJ59g"},"source":["## Problem 1\n","Implement online and batch learning algorithms for\n","- logistic regression,\n","- perceptron,\n","- SVM."]},{"cell_type":"markdown","metadata":{"id":"lrQ2z_vDJ59h"},"source":["## Problem 2\n","Use the online-to-batch conversion of weight averaging\n","\n","$$\n","\\bar{w} = \\left (\\sum_i w^{(i)} \\right) / \\left( N \\times T \\right)\n","$$\n","for all three of your online learning implementations."]},{"cell_type":"code","metadata":{"id":"3Qgb59dtJ59i"},"source":["# This is an object oriented approach using inheritance. The generic Learner class implements methods that\n","# are used by all three learners (Multiclass Perceptron, SVM, Logistic Regression) to avoid code duplication.\n","# The child classes inherit these methods from the Lerner class and only need to implement in what they differ.\n","\n","# You may define each class independently if you wish, or use different mehods within the classes, but again:\n","# Make sure the code blocks at the end work as intended!!!\n","\n","class Learner:\n","    \"\"\"Generic Learner class. Extends into Multiclass Perceptron and Logstic Regression.\"\"\"\n","\n","    def __init__(self, features=4, labels=3, epochs=200):\n","        self.f = features\n","        self.l = labels\n","        self.N = epochs\n","        self.weights = np.zeros(self.f*self.l)\n","\n","    def block_features(self, data, label=None):\n","        \"\"\"Constructs the block feature representation for a data point.\n","\n","        If label is None, returns a matrix with block features for all labels (the columns).\n","        Else, returns a block feature representation for a single lable.\n","\n","        Args:\n","            data: numpy array. The feature representation of the data point.\n","            label: int\n","\n","        Returns:\n","            numpy array (2-dim or 1-dim)\n","        \"\"\"\n","        matrix_feat = []\n","        block_feat = np.zeros(self.f * self.l)\n","        # Your code here\n","        if label is None:\n","          for l in range(self.l):\n","            matrix_feat.append(self.block_features(data, label=l))\n","          return np.array(matrix_feat)\n","        else:\n","          for i in range(len(data[0])):\n","            idx = int((self.f * label) + i)\n","            block_feat[idx] = data[0][i]\n","          return block_feat\n","\n","    def learn_online(self, train, w_avg=False):\n","        \"\"\"Trains the Learner on training data, updating weights after each data point.\n","\n","        Args:\n","            train: Iris data format. The training data\n","            w_avg: Boolean. Defaults to False.\n","                If True, weights are stored during training and averaged after completion.\n","        \"\"\"\n","        # Your code here\n","        self.block_features(train[0])\n","        weights = []\n","        for n in range(self.N):\n","            np.random.shuffle(train)\n","            for i in train:\n","                label_probs = self.label_probabilities(i)\n","                predicted_label = np.argmax(label_probs)\n","                self.weights = self.weights + self.update((i[0], i[1], predicted_label))\n","                weights.append(self.weights)\n","        if w_avg:\n","            self.weights = np.mean(np.array(weights), axis = 0)\n","           # self.weights = np.sum(weights, axis=0)/(len(train)*(self.N-2)) -> wie oben in der Aufgabenstellung\n","\n","    def learn_batch(self, train):\n","        \"\"\"Trains the Learner on training data, updating weights after each epoch.\n","\n","        Args:\n","            train: Iris data format. The training data\n","        \"\"\"\n","        # Your code here\n","        self.weights = np.zeros(self.f*self.l)\n","        for i in range(self.N):\n","            update = np.zeros(len(self.weights))\n","            #np.random.shuffle(train) --> it's not so important\n","            for t in train:\n","                label_prob = self.label_probabilities(t)\n","                predicted_label = np.argmax(label_prob)\n","                update += self.update((t[0], t[1], predicted_label))\n","            self.weights = self.weights + update\n","\n","    def test(self, test):\n","        \"\"\"Test the Learner on test data.\n","\n","        Args:\n","            test: Iris data format. The test data\n","\n","        Returns:\n","            float. Accuracy on the test set\n","        \"\"\"\n","        # Your code here\n","        correct, incorrect = 0,0\n","        for row in test:\n","            label_prob = self.label_probabilities(row)\n","            predicted = np.argmax(label_prob)\n","            if predicted == row[1]:\n","                correct += 1\n","            else:\n","              incorrect += 1\n","        accuracy = (correct * 1.0) / ((correct + incorrect) * 1.0)\n","        return accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ixbkmm4JJ59l"},"source":["class MCP(Learner):\n","    \"\"\"Multiclass Perceptron. Inherits from Learner\"\"\"\n","\n","    def label_probabilities(self, data):\n","        \"\"\"Calculates label probabilities for a data point.\n","\n","        Args:\n","            data: numpy array. The feature representation of the data point.\n","\n","        Returns:\n","            numpy array with length self.l\n","        \"\"\"\n","        # Your code here\n","        label_prob = np.zeros(self.l)\n","        feature = self.block_features(data)\n","        for i in range(self.l):\n","            label_prob[i] = np.dot(feature[i], self.weights)\n","        return label_prob\n","\n","    def update(self, dp):\n","        \"\"\"Calculates the weight update given a single training sample.\n","\n","        Args:\n","            data: list/tuple containing numpy array (features) and int (label)\n","\n","        Returns:\n","            1-dim numpy array\n","        \"\"\"\n","        # Your code here\n","        if dp[1] != dp[2]:\n","         return self.block_features(dp, dp[1]) - self.block_features(dp, dp[2])\n","        else:\n","            return np.zeros(self.f * self.l)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0x6kDFltJ59n"},"source":["class SVM(MCP):\n","    \"\"\"Support Vector Machine. Inherits from MCP (Multiclass Perceptron)\"\"\"\n","\n","    def update(self, dp):\n","        \"\"\"Calculates the weight update given a single training sample.\n","\n","        Args:\n","            data: list/tuple containing numpy array (features) and int (label)\n","\n","        Returns:\n","            1-dim numpy array\n","        \"\"\"\n","        # Your code here\n","        label_prob = self.label_probabilities(dp)\n","        label_correct = label_prob[int(dp[1])]\n","        label_prob = label_prob.tolist()\n","        label_prob.remove(label_correct)\n","        label_incorrect = max(label_prob)\n","\n","        if dp[2] == dp[1]:\n","          return np.zeros(self.f * self.l)\n","        elif (label_correct - label_incorrect) < 1:\n","          return self.block_features(dp, dp[1]) - self.block_features(dp, dp[2])\n","        else:\n","          return np.zeros(self.f * self.l)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0vgD7oiRJ59o"},"source":["class LogReg(Learner):\n","    \"\"\"Logistic Regression. Inherits from Learner.\"\"\"\n","    #man berechnet hier nicht the prediction nur expect von feature vectors\n","    #the predictions werden in Learner berechnet\n","    #was ist die |P diese Werte gewÃ¤hlt zu werden\n","\n","    def label_probabilities(self, data):\n","        \"\"\"Calculates label probabilities for a data point.\n","\n","        Args:\n","            data: numpy array.\n","\n","        Returns:\n","            numpy-array with length self.l\n","        \"\"\"\n","        # Your code here\n","        label_prob = np.zeros(self.l)\n","        block_vector = self.block_features(data)\n","        for i in range(self.l):\n","            label_prob[i] = np.dot(block_vector[i], self.weights)\n","        length = np.sqrt(np.sum(np.square(label_prob)))\n","        if length == 0:\n","            length += 1\n","        for i in range(len(label_prob)):\n","            label_prob[i] /= length\n","        return label_prob\n","\n","    def weighted_feature_sum(self, data):\n","        \"\"\"Sums over the probability-weighted block features of a data point.\n","\n","        Args:\n","            data: numpy array. The feature representation of the data point.\n","\n","        Returns:\n","            1-dim numpy array with length self.l*self.f\n","        \"\"\"\n","        # Your code here\n","        block_vector = self.block_features(data)\n","        label_prob = self.label_probabilities(data)\n","        for i in range(len(block_vector)):\n","            block_vector[i] *= label_prob[i]\n","        return (np.sum(block_vector, axis = 0) - (block_vector[int(data[1])] * label_prob[int(data[1])]))\n","\n","    def update(self, dp):\n","        \"\"\"Calculates the weight update given a single training sample.\n","\n","        Args:\n","            data: list/tuple containing numpy array (features) and int (label)\n","\n","        Returns:\n","            numpy array\n","        \"\"\"\n","        # Your code here\n","        return (self.block_features(dp, dp[1]) - self.weighted_feature_sum(dp))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oObR830kJ59p"},"source":["## Problem 3\n","Apply the algorithms to the iris data and discuss the differences by evaluating the classification error on the test set."]},{"cell_type":"code","metadata":{"id":"Z8MCk0WhJ59q"},"source":["# Data preprocessing. You can copy your solution from Problems 6.\n","def read_data(filename):\n","    \"\"\"\n","    Reads an annotated corpus into a list.\n","\n","    Args:\n","    filename -- str -- The name of the corpus file.\n","\n","    Returns:\n","    documents -- list -- A list of all documents with their corresponding label.\n","    \"\"\"\n","    # YOUR CODE HERE\n","    df = pd.read_csv(filename,header=None)\n","\n","    df[4] = df[4].replace(['Iris-setosa'],0)\n","    df[4] = df[4].replace(['Iris-versicolor'],1)\n","    df[4] = df[4].replace(['Iris-virginica'],2)\n","\n","    return df\n","\n","def split_train_test(data):\n","    \"\"\"\n","    Splits iris.data into training and test sets.\n","    \"\"\"\n","    # YOUR CODE HERE\n","    X = []\n","    y = []\n","    for index, rows in data.iterrows():\n","    # Create list for the current row\n","      if index%4==0:\n","        my_list =[[rows[0], rows[1], rows[2], rows[3]], rows[4]]\n","        y.append(my_list)\n","      else:\n","        my_list =[[rows[0], rows[1], rows[2], rows[3]], rows[4]]\n","        X.append(my_list)\n","    return X,y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cFQ9UhmidkUx"},"source":["data = read_data('iris.csv')\n","train, test = split_train_test(data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dmV3lqPqJgin","executionInfo":{"status":"ok","timestamp":1638868134744,"user_tz":-60,"elapsed":3339,"user":{"displayName":"Denitsa Ilieva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10873287225646224114"}},"outputId":"6a3eafe5-bf49-4b57-e3c2-8feb81e97b08"},"source":["print('MCP with Online Learning and 1000 epochs')\n","epochs = 1000\n","mcp = MCP(epochs=epochs)\n","mcp.test(test)\n","mcp.learn_online(train, w_avg=True)\n","mcp.test(test)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MCP with Online Learning and 1000 epochs\n"]},{"output_type":"execute_result","data":{"text/plain":["0.9473684210526315"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SA0cOkDjiHOR","executionInfo":{"status":"ok","timestamp":1638868141579,"user_tz":-60,"elapsed":3290,"user":{"displayName":"Denitsa Ilieva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10873287225646224114"}},"outputId":"67c0c027-8bdc-4cc0-b8e0-5ee8af5f5320"},"source":["print('MCP with Online Learning and 2000 epochs')\n","epochs = 1000\n","mcp = MCP(epochs=epochs)\n","mcp.test(test)\n","mcp.learn_online(train, w_avg=True)\n","mcp.test(test)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MCP with Online Learning and 2000 epochs\n"]},{"output_type":"execute_result","data":{"text/plain":["0.9473684210526315"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AcuWcb3AGrRi","executionInfo":{"status":"ok","timestamp":1638868162875,"user_tz":-60,"elapsed":3355,"user":{"displayName":"Denitsa Ilieva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10873287225646224114"}},"outputId":"9c81ecc2-a9f7-4b09-ea36-66ab990e33f7"},"source":["print('MCP with Batch Learning and 1000 epochs')\n","epochs = 1000\n","mcp = MCP(epochs=epochs)\n","mcp.test(test)\n","mcp.learn_batch(train)\n","mcp.test(test)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MCP with Batch Learning and 1000 epochs\n"]},{"output_type":"execute_result","data":{"text/plain":["0.9736842105263158"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gkecvI8NJZyO","executionInfo":{"status":"ok","timestamp":1638868184107,"user_tz":-60,"elapsed":6193,"user":{"displayName":"Denitsa Ilieva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10873287225646224114"}},"outputId":"be275206-d0cc-4dfd-9b59-184a9441803c"},"source":["print('MCP with Batch Learning and 2000 epochs')\n","epochs = 2000\n","mcp = MCP(epochs=epochs)\n","mcp.test(test)\n","mcp.learn_batch(train)\n","mcp.test(test)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MCP with Batch Learning and 2000 epochs\n"]},{"output_type":"execute_result","data":{"text/plain":["0.9736842105263158"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"32Amkv30HiE0","executionInfo":{"status":"ok","timestamp":1638868249951,"user_tz":-60,"elapsed":12032,"user":{"displayName":"Denitsa Ilieva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10873287225646224114"}},"outputId":"f88b32d9-1be4-4272-e813-1996ef425476"},"source":["print('SVM with Online Learning and 2000 epochs')\n","epochs = 2000\n","svm = SVM(epochs = epochs)\n","svm.test(test)\n","svm.learn_online(train, w_avg=True)\n","svm.test(test)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["SVM with Online Learning and 2000 epochs\n"]},{"output_type":"execute_result","data":{"text/plain":["0.9473684210526315"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2fRe5uSCKVPy","executionInfo":{"status":"ok","timestamp":1638868295386,"user_tz":-60,"elapsed":6166,"user":{"displayName":"Denitsa Ilieva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10873287225646224114"}},"outputId":"dde5f319-814a-4eda-f394-2d6db2670498"},"source":["print('SVM with Online Learning and 1000 epochs')\n","epochs = 1000\n","svm = SVM(epochs = epochs)\n","svm.test(test)\n","svm.learn_online(train, w_avg=True)\n","svm.test(test)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["SVM with Online Learning and 1000 epochs\n"]},{"output_type":"execute_result","data":{"text/plain":["0.9473684210526315"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aC13DNg5xMcv","executionInfo":{"status":"ok","timestamp":1638868309638,"user_tz":-60,"elapsed":11606,"user":{"displayName":"Denitsa Ilieva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10873287225646224114"}},"outputId":"d4351993-7f2d-43db-f07c-2a0a16421b87"},"source":["print('SVM with Batch Learning and 2000 epochs')\n","epochs = 2000\n","svm = SVM(epochs = epochs)\n","svm.test(test)\n","svm.learn_batch(train)\n","svm.test(test)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["SVM with Batch Learning and 2000 epochs\n"]},{"output_type":"execute_result","data":{"text/plain":["0.9736842105263158"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QVcfk3IBKbLg","executionInfo":{"status":"ok","timestamp":1638868324190,"user_tz":-60,"elapsed":6295,"user":{"displayName":"Denitsa Ilieva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10873287225646224114"}},"outputId":"2405b4a2-7e6a-45ed-c1b6-60f43137c627"},"source":["print('SVM with Batch Learning and 1000 epochs')\n","epochs = 1000\n","svm = SVM(epochs = epochs)\n","svm.test(test)\n","svm.learn_batch(train)\n","svm.test(test)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["SVM with Batch Learning and 1000 epochs\n"]},{"output_type":"execute_result","data":{"text/plain":["0.9736842105263158"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y9btHCpnH063","executionInfo":{"status":"ok","timestamp":1638869095843,"user_tz":-60,"elapsed":14870,"user":{"displayName":"Denitsa Ilieva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10873287225646224114"}},"outputId":"33903fdd-0841-492a-9cb2-5c1fe36a1c4d"},"source":["print('LogReg with Online Learning and 1000 epochs')\n","epochs = 1000\n","lreg = LogReg(epochs=epochs)\n","lreg.test(test)\n","lreg.learn_online(train, w_avg=True)\n","lreg.test(test)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["LogReg with Online Learning and 1000 epochs\n"]},{"output_type":"execute_result","data":{"text/plain":["0.6842105263157895"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yPJ8OoVoKnsr","executionInfo":{"status":"ok","timestamp":1638869124455,"user_tz":-60,"elapsed":25750,"user":{"displayName":"Denitsa Ilieva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10873287225646224114"}},"outputId":"e2cae6ce-d71f-4e2d-e3dc-ecee2b60ebda"},"source":["print('LogReg with Online Learning and 2000 epochs')\n","epochs = 2000\n","lreg = LogReg(epochs=epochs)\n","lreg.test(test)\n","lreg.learn_online(train, w_avg=True)\n","lreg.test(test)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["LogReg with Online Learning and 2000 epochs\n"]},{"output_type":"execute_result","data":{"text/plain":["0.6842105263157895"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e1FOGRsiD0tk","executionInfo":{"status":"ok","timestamp":1638869141180,"user_tz":-60,"elapsed":12894,"user":{"displayName":"Denitsa Ilieva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10873287225646224114"}},"outputId":"7c930073-3ed1-46fd-b939-446bdb4b1d18"},"source":["print('LogReg with Batch Learning and 1000 epochs')\n","epochs = 1000\n","lreg = LogReg(epochs=epochs)\n","lreg.test(test)\n","lreg.learn_batch(train)\n","lreg.test(test)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["LogReg with Batch Learning and 1000 epochs\n"]},{"output_type":"execute_result","data":{"text/plain":["0.6842105263157895"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7iaYDdBvK2Dk","executionInfo":{"status":"ok","timestamp":1638869172774,"user_tz":-60,"elapsed":26058,"user":{"displayName":"Denitsa Ilieva","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10873287225646224114"}},"outputId":"5ac924b3-2630-426f-9b7c-76e7649b0b62"},"source":["print('LogReg with Batch Learning and 2000 epochs')\n","epochs = 2000\n","lreg = LogReg(epochs=epochs)\n","lreg.test(test)\n","lreg.learn_batch(train)\n","lreg.test(test)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["LogReg with Batch Learning and 2000 epochs\n"]},{"output_type":"execute_result","data":{"text/plain":["0.6842105263157895"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"Hvgb_AE8J59r"},"source":["Specify the number of epochs you used, whether you shuffled the training data, etc.\n","\n","**Results:**<br>\n","\n","Better results are achieved with MCP and SVM if the model is trained with batch learning. The models are trained with 2000 and 1000 epochs, although in this case there is no difference between the results. The training data is always shuffled.\n","\n","For logistic regression the accuracy always remains the same for all trined models."]},{"cell_type":"code","metadata":{"id":"UDF327lnMvyD"},"source":[],"execution_count":null,"outputs":[]}]}